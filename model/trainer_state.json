{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 11.03448275862069,
  "eval_steps": 400,
  "global_step": 2400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05,
      "learning_rate": 4e-05,
      "loss": 1.1122,
      "step": 10
    },
    {
      "epoch": 0.09,
      "learning_rate": 8e-05,
      "loss": 0.9283,
      "step": 20
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00012,
      "loss": 0.8589,
      "step": 30
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00016,
      "loss": 0.8435,
      "step": 40
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0002,
      "loss": 0.8848,
      "step": 50
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00024,
      "loss": 0.8028,
      "step": 60
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.7244,
      "step": 70
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00032,
      "loss": 0.7072,
      "step": 80
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.6546,
      "step": 90
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0004,
      "loss": 0.7469,
      "step": 100
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00044,
      "loss": 0.6898,
      "step": 110
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00048,
      "loss": 0.6463,
      "step": 120
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0005200000000000001,
      "loss": 0.7089,
      "step": 130
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0005600000000000001,
      "loss": 0.6943,
      "step": 140
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0006,
      "loss": 0.7213,
      "step": 150
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00064,
      "loss": 0.6888,
      "step": 160
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00068,
      "loss": 0.6677,
      "step": 170
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0007199999999999999,
      "loss": 0.6248,
      "step": 180
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00076,
      "loss": 0.6436,
      "step": 190
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0008,
      "loss": 0.6914,
      "step": 200
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00084,
      "loss": 0.6902,
      "step": 210
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00088,
      "loss": 0.6878,
      "step": 220
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00092,
      "loss": 0.6632,
      "step": 230
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00096,
      "loss": 0.6188,
      "step": 240
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.001,
      "loss": 0.6723,
      "step": 250
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0010400000000000001,
      "loss": 0.6689,
      "step": 260
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00108,
      "loss": 0.7905,
      "step": 270
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0011200000000000001,
      "loss": 0.6825,
      "step": 280
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00116,
      "loss": 0.6913,
      "step": 290
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0012,
      "loss": 0.6822,
      "step": 300
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00124,
      "loss": 0.7374,
      "step": 310
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00128,
      "loss": 0.8024,
      "step": 320
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00132,
      "loss": 0.8113,
      "step": 330
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00136,
      "loss": 0.7632,
      "step": 340
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0014,
      "loss": 0.7306,
      "step": 350
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0014399999999999999,
      "loss": 0.8561,
      "step": 360
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00148,
      "loss": 0.9161,
      "step": 370
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00152,
      "loss": 0.8023,
      "step": 380
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0015600000000000002,
      "loss": 0.7472,
      "step": 390
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0016,
      "loss": 0.7658,
      "step": 400
    },
    {
      "epoch": 1.84,
      "eval_loss": 0.8541677594184875,
      "eval_runtime": 120.8134,
      "eval_samples_per_second": 13.633,
      "eval_steps_per_second": 1.705,
      "eval_wer": 0.8780512715759371,
      "step": 400
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00164,
      "loss": 0.8812,
      "step": 410
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00168,
      "loss": 0.9483,
      "step": 420
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00172,
      "loss": 0.9009,
      "step": 430
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.00176,
      "loss": 0.9542,
      "step": 440
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0018000000000000002,
      "loss": 0.8006,
      "step": 450
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00184,
      "loss": 0.7263,
      "step": 460
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00188,
      "loss": 0.7121,
      "step": 470
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00192,
      "loss": 0.7879,
      "step": 480
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00196,
      "loss": 0.9336,
      "step": 490
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.002,
      "loss": 0.7588,
      "step": 500
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0019966722129783694,
      "loss": 0.8798,
      "step": 510
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.001993344425956739,
      "loss": 0.8457,
      "step": 520
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.001990016638935108,
      "loss": 0.8996,
      "step": 530
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0019866888519134776,
      "loss": 0.9526,
      "step": 540
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.001983361064891847,
      "loss": 0.8699,
      "step": 550
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0019800332778702164,
      "loss": 0.84,
      "step": 560
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0019767054908485858,
      "loss": 0.909,
      "step": 570
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.001973377703826955,
      "loss": 0.886,
      "step": 580
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0019700499168053246,
      "loss": 1.0063,
      "step": 590
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.001966722129783694,
      "loss": 0.9144,
      "step": 600
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0019633943427620633,
      "loss": 0.9008,
      "step": 610
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0019600665557404327,
      "loss": 0.9441,
      "step": 620
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.001956738768718802,
      "loss": 0.9381,
      "step": 630
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0019534109816971715,
      "loss": 1.0956,
      "step": 640
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.001950083194675541,
      "loss": 0.991,
      "step": 650
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.0019467554076539103,
      "loss": 0.9414,
      "step": 660
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.0019434276206322797,
      "loss": 0.7518,
      "step": 670
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.001940099833610649,
      "loss": 0.819,
      "step": 680
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0019367720465890185,
      "loss": 0.8068,
      "step": 690
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.0019334442595673879,
      "loss": 0.8188,
      "step": 700
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0019301164725457572,
      "loss": 0.8443,
      "step": 710
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0019267886855241266,
      "loss": 0.7888,
      "step": 720
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.001923460898502496,
      "loss": 0.7724,
      "step": 730
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.0019201331114808654,
      "loss": 0.818,
      "step": 740
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.0019168053244592348,
      "loss": 0.9474,
      "step": 750
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0019134775374376042,
      "loss": 0.9435,
      "step": 760
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.0019101497504159736,
      "loss": 0.7615,
      "step": 770
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.001906821963394343,
      "loss": 0.8235,
      "step": 780
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.0019034941763727124,
      "loss": 0.8374,
      "step": 790
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0019001663893510818,
      "loss": 0.9419,
      "step": 800
    },
    {
      "epoch": 3.68,
      "eval_loss": 0.9189423322677612,
      "eval_runtime": 121.9886,
      "eval_samples_per_second": 13.501,
      "eval_steps_per_second": 1.689,
      "eval_wer": 0.9035849249310591,
      "step": 800
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.001896838602329451,
      "loss": 0.8739,
      "step": 810
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.0018935108153078203,
      "loss": 0.8121,
      "step": 820
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.0018901830282861897,
      "loss": 0.7791,
      "step": 830
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.0018868552412645591,
      "loss": 0.815,
      "step": 840
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.0018835274542429285,
      "loss": 0.8608,
      "step": 850
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.001880199667221298,
      "loss": 0.8538,
      "step": 860
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.0018768718801996673,
      "loss": 0.9205,
      "step": 870
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.0018735440931780365,
      "loss": 0.7929,
      "step": 880
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.0018702163061564058,
      "loss": 0.7434,
      "step": 890
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.0018668885191347752,
      "loss": 0.7084,
      "step": 900
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.0018635607321131446,
      "loss": 0.706,
      "step": 910
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.001860232945091514,
      "loss": 0.8154,
      "step": 920
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.0018569051580698834,
      "loss": 0.7653,
      "step": 930
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.0018535773710482528,
      "loss": 0.7371,
      "step": 940
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.0018502495840266222,
      "loss": 0.6829,
      "step": 950
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.0018469217970049916,
      "loss": 0.8075,
      "step": 960
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.001843594009983361,
      "loss": 0.8531,
      "step": 970
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.0018402662229617304,
      "loss": 0.7563,
      "step": 980
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.0018369384359400998,
      "loss": 0.7466,
      "step": 990
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.0018336106489184691,
      "loss": 0.7449,
      "step": 1000
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.0018302828618968385,
      "loss": 0.7808,
      "step": 1010
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.001826955074875208,
      "loss": 0.7971,
      "step": 1020
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.0018236272878535773,
      "loss": 0.7999,
      "step": 1030
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.0018202995008319467,
      "loss": 0.6595,
      "step": 1040
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.001816971713810316,
      "loss": 0.7197,
      "step": 1050
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.0018136439267886855,
      "loss": 0.7425,
      "step": 1060
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.0018103161397670549,
      "loss": 0.781,
      "step": 1070
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.0018069883527454243,
      "loss": 0.7268,
      "step": 1080
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.0018036605657237937,
      "loss": 0.7264,
      "step": 1090
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.001800332778702163,
      "loss": 0.6392,
      "step": 1100
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.0017970049916805324,
      "loss": 0.5919,
      "step": 1110
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.0017936772046589018,
      "loss": 0.6316,
      "step": 1120
    },
    {
      "epoch": 5.2,
      "learning_rate": 0.0017903494176372712,
      "loss": 0.6685,
      "step": 1130
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.0017870216306156406,
      "loss": 0.7215,
      "step": 1140
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.00178369384359401,
      "loss": 0.7579,
      "step": 1150
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.0017803660565723794,
      "loss": 0.6023,
      "step": 1160
    },
    {
      "epoch": 5.38,
      "learning_rate": 0.0017770382695507488,
      "loss": 0.597,
      "step": 1170
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.0017737104825291182,
      "loss": 0.6519,
      "step": 1180
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.0017703826955074876,
      "loss": 0.7605,
      "step": 1190
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.001767054908485857,
      "loss": 0.6849,
      "step": 1200
    },
    {
      "epoch": 5.52,
      "eval_loss": 0.8133845329284668,
      "eval_runtime": 123.1815,
      "eval_samples_per_second": 13.371,
      "eval_steps_per_second": 1.672,
      "eval_wer": 0.8435297722398121,
      "step": 1200
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.0017637271214642264,
      "loss": 0.6384,
      "step": 1210
    },
    {
      "epoch": 5.61,
      "learning_rate": 0.0017603993344425957,
      "loss": 0.724,
      "step": 1220
    },
    {
      "epoch": 5.66,
      "learning_rate": 0.0017570715474209651,
      "loss": 0.6758,
      "step": 1230
    },
    {
      "epoch": 5.7,
      "learning_rate": 0.0017537437603993345,
      "loss": 0.7162,
      "step": 1240
    },
    {
      "epoch": 5.75,
      "learning_rate": 0.001750415973377704,
      "loss": 0.7188,
      "step": 1250
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.0017470881863560733,
      "loss": 0.6729,
      "step": 1260
    },
    {
      "epoch": 5.84,
      "learning_rate": 0.0017437603993344427,
      "loss": 0.6844,
      "step": 1270
    },
    {
      "epoch": 5.89,
      "learning_rate": 0.001740432612312812,
      "loss": 0.7018,
      "step": 1280
    },
    {
      "epoch": 5.93,
      "learning_rate": 0.0017371048252911815,
      "loss": 0.7493,
      "step": 1290
    },
    {
      "epoch": 5.98,
      "learning_rate": 0.0017337770382695509,
      "loss": 0.7825,
      "step": 1300
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.0017304492512479203,
      "loss": 0.7275,
      "step": 1310
    },
    {
      "epoch": 6.07,
      "learning_rate": 0.0017271214642262897,
      "loss": 0.6095,
      "step": 1320
    },
    {
      "epoch": 6.11,
      "learning_rate": 0.001723793677204659,
      "loss": 0.6023,
      "step": 1330
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.0017204658901830284,
      "loss": 0.6442,
      "step": 1340
    },
    {
      "epoch": 6.21,
      "learning_rate": 0.0017171381031613978,
      "loss": 0.628,
      "step": 1350
    },
    {
      "epoch": 6.25,
      "learning_rate": 0.0017138103161397672,
      "loss": 0.7425,
      "step": 1360
    },
    {
      "epoch": 6.3,
      "learning_rate": 0.0017104825291181366,
      "loss": 0.6118,
      "step": 1370
    },
    {
      "epoch": 6.34,
      "learning_rate": 0.001707154742096506,
      "loss": 0.5955,
      "step": 1380
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.0017038269550748754,
      "loss": 0.6236,
      "step": 1390
    },
    {
      "epoch": 6.44,
      "learning_rate": 0.0017004991680532448,
      "loss": 0.604,
      "step": 1400
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.001697171381031614,
      "loss": 0.7017,
      "step": 1410
    },
    {
      "epoch": 6.53,
      "learning_rate": 0.0016938435940099833,
      "loss": 0.6458,
      "step": 1420
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.0016905158069883527,
      "loss": 0.5871,
      "step": 1430
    },
    {
      "epoch": 6.62,
      "learning_rate": 0.0016871880199667221,
      "loss": 0.6093,
      "step": 1440
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.0016838602329450915,
      "loss": 0.6975,
      "step": 1450
    },
    {
      "epoch": 6.71,
      "learning_rate": 0.001680532445923461,
      "loss": 0.7242,
      "step": 1460
    },
    {
      "epoch": 6.76,
      "learning_rate": 0.0016772046589018303,
      "loss": 0.6451,
      "step": 1470
    },
    {
      "epoch": 6.8,
      "learning_rate": 0.0016738768718801997,
      "loss": 0.6797,
      "step": 1480
    },
    {
      "epoch": 6.85,
      "learning_rate": 0.001670549084858569,
      "loss": 0.6696,
      "step": 1490
    },
    {
      "epoch": 6.9,
      "learning_rate": 0.0016672212978369385,
      "loss": 0.6674,
      "step": 1500
    },
    {
      "epoch": 6.94,
      "learning_rate": 0.0016638935108153079,
      "loss": 0.7674,
      "step": 1510
    },
    {
      "epoch": 6.99,
      "learning_rate": 0.0016605657237936773,
      "loss": 0.6612,
      "step": 1520
    },
    {
      "epoch": 7.03,
      "learning_rate": 0.0016572379367720466,
      "loss": 0.6354,
      "step": 1530
    },
    {
      "epoch": 7.08,
      "learning_rate": 0.001653910149750416,
      "loss": 0.5512,
      "step": 1540
    },
    {
      "epoch": 7.13,
      "learning_rate": 0.0016505823627287854,
      "loss": 0.5646,
      "step": 1550
    },
    {
      "epoch": 7.17,
      "learning_rate": 0.0016472545757071548,
      "loss": 0.542,
      "step": 1560
    },
    {
      "epoch": 7.22,
      "learning_rate": 0.0016439267886855242,
      "loss": 0.5691,
      "step": 1570
    },
    {
      "epoch": 7.26,
      "learning_rate": 0.0016405990016638936,
      "loss": 0.5858,
      "step": 1580
    },
    {
      "epoch": 7.31,
      "learning_rate": 0.001637271214642263,
      "loss": 0.5383,
      "step": 1590
    },
    {
      "epoch": 7.36,
      "learning_rate": 0.0016339434276206324,
      "loss": 0.5424,
      "step": 1600
    },
    {
      "epoch": 7.36,
      "eval_loss": 0.8558240532875061,
      "eval_runtime": 123.5314,
      "eval_samples_per_second": 13.333,
      "eval_steps_per_second": 1.668,
      "eval_wer": 0.8839750791543254,
      "step": 1600
    },
    {
      "epoch": 7.4,
      "learning_rate": 0.0016306156405990018,
      "loss": 0.5358,
      "step": 1610
    },
    {
      "epoch": 7.45,
      "learning_rate": 0.0016272878535773712,
      "loss": 0.5409,
      "step": 1620
    },
    {
      "epoch": 7.49,
      "learning_rate": 0.0016239600665557403,
      "loss": 0.6214,
      "step": 1630
    },
    {
      "epoch": 7.54,
      "learning_rate": 0.0016206322795341097,
      "loss": 0.5499,
      "step": 1640
    },
    {
      "epoch": 7.59,
      "learning_rate": 0.0016173044925124791,
      "loss": 0.51,
      "step": 1650
    },
    {
      "epoch": 7.63,
      "learning_rate": 0.0016139767054908485,
      "loss": 0.5653,
      "step": 1660
    },
    {
      "epoch": 7.68,
      "learning_rate": 0.001610648918469218,
      "loss": 0.5585,
      "step": 1670
    },
    {
      "epoch": 7.72,
      "learning_rate": 0.0016073211314475873,
      "loss": 0.5769,
      "step": 1680
    },
    {
      "epoch": 7.77,
      "learning_rate": 0.0016039933444259567,
      "loss": 0.5737,
      "step": 1690
    },
    {
      "epoch": 7.82,
      "learning_rate": 0.001600665557404326,
      "loss": 0.5538,
      "step": 1700
    },
    {
      "epoch": 7.86,
      "learning_rate": 0.0015973377703826955,
      "loss": 0.5813,
      "step": 1710
    },
    {
      "epoch": 7.91,
      "learning_rate": 0.0015940099833610648,
      "loss": 0.6276,
      "step": 1720
    },
    {
      "epoch": 7.95,
      "learning_rate": 0.0015906821963394342,
      "loss": 0.6326,
      "step": 1730
    },
    {
      "epoch": 8.0,
      "learning_rate": 0.0015873544093178036,
      "loss": 0.6049,
      "step": 1740
    },
    {
      "epoch": 8.05,
      "learning_rate": 0.001584026622296173,
      "loss": 0.5116,
      "step": 1750
    },
    {
      "epoch": 8.09,
      "learning_rate": 0.0015806988352745424,
      "loss": 0.4557,
      "step": 1760
    },
    {
      "epoch": 8.14,
      "learning_rate": 0.0015773710482529118,
      "loss": 0.4551,
      "step": 1770
    },
    {
      "epoch": 8.18,
      "learning_rate": 0.0015740432612312812,
      "loss": 0.4633,
      "step": 1780
    },
    {
      "epoch": 8.23,
      "learning_rate": 0.0015707154742096506,
      "loss": 0.5605,
      "step": 1790
    },
    {
      "epoch": 8.28,
      "learning_rate": 0.00156738768718802,
      "loss": 0.469,
      "step": 1800
    },
    {
      "epoch": 8.32,
      "learning_rate": 0.0015640599001663894,
      "loss": 0.4925,
      "step": 1810
    },
    {
      "epoch": 8.37,
      "learning_rate": 0.0015607321131447588,
      "loss": 0.5085,
      "step": 1820
    },
    {
      "epoch": 8.41,
      "learning_rate": 0.0015574043261231281,
      "loss": 0.5228,
      "step": 1830
    },
    {
      "epoch": 8.46,
      "learning_rate": 0.0015540765391014975,
      "loss": 0.5601,
      "step": 1840
    },
    {
      "epoch": 8.51,
      "learning_rate": 0.001550748752079867,
      "loss": 0.5364,
      "step": 1850
    },
    {
      "epoch": 8.55,
      "learning_rate": 0.0015474209650582363,
      "loss": 0.4915,
      "step": 1860
    },
    {
      "epoch": 8.6,
      "learning_rate": 0.0015440931780366057,
      "loss": 0.4938,
      "step": 1870
    },
    {
      "epoch": 8.64,
      "learning_rate": 0.001540765391014975,
      "loss": 0.5517,
      "step": 1880
    },
    {
      "epoch": 8.69,
      "learning_rate": 0.0015374376039933445,
      "loss": 0.568,
      "step": 1890
    },
    {
      "epoch": 8.74,
      "learning_rate": 0.0015341098169717139,
      "loss": 0.5242,
      "step": 1900
    },
    {
      "epoch": 8.78,
      "learning_rate": 0.0015307820299500833,
      "loss": 0.5129,
      "step": 1910
    },
    {
      "epoch": 8.83,
      "learning_rate": 0.0015274542429284527,
      "loss": 0.5469,
      "step": 1920
    },
    {
      "epoch": 8.87,
      "learning_rate": 0.001524126455906822,
      "loss": 0.5061,
      "step": 1930
    },
    {
      "epoch": 8.92,
      "learning_rate": 0.0015207986688851914,
      "loss": 0.563,
      "step": 1940
    },
    {
      "epoch": 8.97,
      "learning_rate": 0.0015174708818635608,
      "loss": 0.5448,
      "step": 1950
    },
    {
      "epoch": 9.01,
      "learning_rate": 0.0015141430948419302,
      "loss": 0.5419,
      "step": 1960
    },
    {
      "epoch": 9.06,
      "learning_rate": 0.0015108153078202996,
      "loss": 0.4387,
      "step": 1970
    },
    {
      "epoch": 9.1,
      "learning_rate": 0.001507487520798669,
      "loss": 0.4126,
      "step": 1980
    },
    {
      "epoch": 9.15,
      "learning_rate": 0.0015041597337770384,
      "loss": 0.4267,
      "step": 1990
    },
    {
      "epoch": 9.2,
      "learning_rate": 0.0015008319467554078,
      "loss": 0.4478,
      "step": 2000
    },
    {
      "epoch": 9.2,
      "eval_loss": 0.8323544263839722,
      "eval_runtime": 124.9727,
      "eval_samples_per_second": 13.179,
      "eval_steps_per_second": 1.648,
      "eval_wer": 0.8198345419262588,
      "step": 2000
    },
    {
      "epoch": 9.24,
      "learning_rate": 0.001497504159733777,
      "loss": 0.5055,
      "step": 2010
    },
    {
      "epoch": 9.29,
      "learning_rate": 0.0014941763727121464,
      "loss": 0.4691,
      "step": 2020
    },
    {
      "epoch": 9.33,
      "learning_rate": 0.0014908485856905157,
      "loss": 0.4027,
      "step": 2030
    },
    {
      "epoch": 9.38,
      "learning_rate": 0.0014875207986688851,
      "loss": 0.467,
      "step": 2040
    },
    {
      "epoch": 9.43,
      "learning_rate": 0.0014841930116472545,
      "loss": 0.5058,
      "step": 2050
    },
    {
      "epoch": 9.47,
      "learning_rate": 0.001480865224625624,
      "loss": 0.5528,
      "step": 2060
    },
    {
      "epoch": 9.52,
      "learning_rate": 0.0014775374376039933,
      "loss": 0.5128,
      "step": 2070
    },
    {
      "epoch": 9.56,
      "learning_rate": 0.0014742096505823627,
      "loss": 0.4479,
      "step": 2080
    },
    {
      "epoch": 9.61,
      "learning_rate": 0.001470881863560732,
      "loss": 0.4735,
      "step": 2090
    },
    {
      "epoch": 9.66,
      "learning_rate": 0.0014675540765391015,
      "loss": 0.4811,
      "step": 2100
    },
    {
      "epoch": 9.7,
      "learning_rate": 0.001464559068219634,
      "loss": 0.5063,
      "step": 2110
    },
    {
      "epoch": 9.75,
      "learning_rate": 0.0014612312811980034,
      "loss": 0.4951,
      "step": 2120
    },
    {
      "epoch": 9.79,
      "learning_rate": 0.0014579034941763728,
      "loss": 0.4818,
      "step": 2130
    },
    {
      "epoch": 9.84,
      "learning_rate": 0.0014545757071547422,
      "loss": 0.4383,
      "step": 2140
    },
    {
      "epoch": 9.89,
      "learning_rate": 0.0014512479201331115,
      "loss": 0.4888,
      "step": 2150
    },
    {
      "epoch": 9.93,
      "learning_rate": 0.001447920133111481,
      "loss": 0.5127,
      "step": 2160
    },
    {
      "epoch": 9.98,
      "learning_rate": 0.0014445923460898503,
      "loss": 0.476,
      "step": 2170
    },
    {
      "epoch": 10.02,
      "learning_rate": 0.0014412645590682197,
      "loss": 0.5235,
      "step": 2180
    },
    {
      "epoch": 10.07,
      "learning_rate": 0.001437936772046589,
      "loss": 0.4218,
      "step": 2190
    },
    {
      "epoch": 10.11,
      "learning_rate": 0.0014346089850249585,
      "loss": 0.3952,
      "step": 2200
    },
    {
      "epoch": 10.16,
      "learning_rate": 0.0014312811980033279,
      "loss": 0.4281,
      "step": 2210
    },
    {
      "epoch": 10.21,
      "learning_rate": 0.0014279534109816973,
      "loss": 0.4444,
      "step": 2220
    },
    {
      "epoch": 10.25,
      "learning_rate": 0.0014246256239600667,
      "loss": 0.5159,
      "step": 2230
    },
    {
      "epoch": 10.3,
      "learning_rate": 0.001421297836938436,
      "loss": 0.4102,
      "step": 2240
    },
    {
      "epoch": 10.34,
      "learning_rate": 0.0014179700499168052,
      "loss": 0.4288,
      "step": 2250
    },
    {
      "epoch": 10.39,
      "learning_rate": 0.0014146422628951746,
      "loss": 0.4195,
      "step": 2260
    },
    {
      "epoch": 10.44,
      "learning_rate": 0.001411314475873544,
      "loss": 0.4572,
      "step": 2270
    },
    {
      "epoch": 10.48,
      "learning_rate": 0.0014079866888519134,
      "loss": 0.4728,
      "step": 2280
    },
    {
      "epoch": 10.53,
      "learning_rate": 0.0014046589018302828,
      "loss": 0.4206,
      "step": 2290
    },
    {
      "epoch": 10.57,
      "learning_rate": 0.0014013311148086522,
      "loss": 0.3904,
      "step": 2300
    },
    {
      "epoch": 10.62,
      "learning_rate": 0.0013980033277870216,
      "loss": 0.4572,
      "step": 2310
    },
    {
      "epoch": 10.67,
      "learning_rate": 0.001394675540765391,
      "loss": 0.4876,
      "step": 2320
    },
    {
      "epoch": 10.71,
      "learning_rate": 0.0013913477537437604,
      "loss": 0.533,
      "step": 2330
    },
    {
      "epoch": 10.76,
      "learning_rate": 0.0013880199667221297,
      "loss": 0.4331,
      "step": 2340
    },
    {
      "epoch": 10.8,
      "learning_rate": 0.0013846921797004991,
      "loss": 0.4424,
      "step": 2350
    },
    {
      "epoch": 10.85,
      "learning_rate": 0.0013813643926788685,
      "loss": 0.3879,
      "step": 2360
    },
    {
      "epoch": 10.9,
      "learning_rate": 0.001378036605657238,
      "loss": 0.5029,
      "step": 2370
    },
    {
      "epoch": 10.94,
      "learning_rate": 0.0013747088186356073,
      "loss": 0.4677,
      "step": 2380
    },
    {
      "epoch": 10.99,
      "learning_rate": 0.0013713810316139767,
      "loss": 0.4758,
      "step": 2390
    },
    {
      "epoch": 11.03,
      "learning_rate": 0.001368053244592346,
      "loss": 0.4507,
      "step": 2400
    },
    {
      "epoch": 11.03,
      "eval_loss": 0.8285505771636963,
      "eval_runtime": 124.676,
      "eval_samples_per_second": 13.21,
      "eval_steps_per_second": 1.652,
      "eval_wer": 0.8033908691655602,
      "step": 2400
    }
  ],
  "logging_steps": 10,
  "max_steps": 6510,
  "num_train_epochs": 30,
  "save_steps": 400,
  "total_flos": 4.709861880132585e+18,
  "trial_name": null,
  "trial_params": null
}
